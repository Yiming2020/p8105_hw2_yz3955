---
title: "Homework 2"
author: Yiming Zhao
output: github_document
---

This is my solution for HW2

```{r}
library(tidyverse)
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset.

```{r}
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data for  2018 and 2017.

```{r}
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation

```{r}
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017) 

precip_comb1718 = left_join(precip_df, month_df,by = "month") %>% 
  relocate(year, month, month_name)
```

This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trash wheel collects that trash, and stores it into a dumpsters. The dataset contains information on year, month, and trash collected, includes some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` rows in our final trash wheel collection dataset. And the key variables for the trash wheel collection dataset : `r names(trashwheel_df)`. 

Additional data sheets include month precipitation data for year 2017 and year 2018 are presented in this file. There are a total of `r nrow(precip_comb1718)` rows in our final month precipitation dataset. And the key variables for the month precipitation dataset : month_name, total and year.  

For year 2018, the total precipitation is `r select(precip_2018,total) %>% sum()`

The median number of sports balls in a dumpster in 2017 is `r median(filter(trashwheel_df, year == 2017)$sports_balls)`


## Problem 2

Read and clean the data

```{r}
nyc_tran_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE), vending = recode(vending, "YES" = TRUE, "NO" = FALSE))
 
```

There are `r ncol(nyc_tran_df)` variables containing in the dataset: `r names(nyc_tran_df)`.  
In order to clean dataset, I read the csv file at first. And then clean its variable names. Next, I selected the interested variables from the orginal dataset. Then I converted entry and vending variables from character(YES/NO) to a logical variable. Finally, I got a `r nrow(nyc_tran_df)` x `r ncol(nyc_tran_df)` size of the resulting dataset. These data are tidy, but they can make more tidy for different purposes.
  
  
Identify distinct stations:
```{r}
nyc_station = 
  distinct(nyc_tran_df, line, station_name, .keep_all = T)
```

• After calculation, there are `r nrow(nyc_station)` distinct stations, which are identified by name and line.  
• Moreover, there are `r nrow(filter(nyc_station, ada == TRUE))` distinct stations are ADA compliant.  
• As there are `r nrow(filter(nyc_tran_df, vending == FALSE))` stations entrances / exits that do not have vending, and there are `r nrow(filter(nyc_tran_df, vending == FALSE, entry == TRUE))` stations entrances / exits that allow entrance but do not have vendings, so the proportion of station entrances/exits without vending allow entrance is `r nrow(filter(nyc_tran_df, vending == FALSE, entry == TRUE))/nrow(filter(nyc_tran_df, vending == FALSE))`
  
  
Reformat data

```{r}
nyc_reform_df = 
  nyc_station %>% 
  mutate(route8 = as.character(route8), route9 = as.character(route9), 
         route10 = as.character(route10),route11 = as.character(route11)) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_name",
    values_to = "route_value"
  )
```

• There are `r nrow(filter(nyc_reform_df, route_value == "A"))` distinct stations serve the A train.  
• In addition, there are `r nrow(filter(nyc_reform_df, route_value == "A", ada == TRUE))` distinct stations that serve the A train are ADA compliant.  


## Problem 3

First clean the data in pols-month.csv

```{r}
pols_month_df = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  separate(mon, into = c("year", "month", "day")) %>% 
  mutate(month = as.numeric(month), 
         year = as.numeric((year)),
         president = ifelse(prez_dem == 1, "dem", "gop")) %>% 
  left_join(month_df, by = "month") %>%
  subset(select = c(-prez_dem, -prez_gop, -day, -month)) %>% 
  relocate(year, month_name)
```

Second, clean the data in snp.csv

```{r}
snp_df = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  separate(date, into = c("month", "day", "year")) %>% 
  mutate(year = as.numeric(year),
         month = as.numeric(month)
         ) %>% 
  left_join(month_df, by = "month") %>% 
  arrange(year, month, .by_group = FALSE) %>% 
  relocate(year, month_name, day, close) %>% 
  subset(select = c(-month, -day))
```

Third tidy the unemployment data

```{r}
month_abb_df = 
  tibble(
    month_abb = month.abb,
    month_name = month.name
    )

unemploy_df = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>%
  pivot_longer(
    Jan:Dec,
    names_to = "month_abb",
    values_to = "unemployment_value"
    ) %>% 
  left_join(month_abb_df, by = "month_abb") %>% 
  subset(select = -month_abb) %>% 
  janitor::clean_names() %>% 
  relocate(year, month_name) %>% 
  drop_na(unemployment_value)

```

Join the datasets by merging snp into pols, and merging unemployment into the result

```{r}
polssnp_unem_df = 
  left_join(pols_month_df, snp_df, by = c("year", "month_name")) %>% 
  left_join(unemploy_df,by = c("year", "month_name"))
```

For the pols_month_df dataset, it contains `r ncol(pols_month_df)` variables from Jan.1947 to Jun.2015：`r names(pols_month_df)`. For the snp_df dataset, it contains close values from Jan in 1950 to July in 2015. For unemploy_df dataset, it contains unemployment values from Jan in 1948 to Jun in 2015. After cleaning above three datasets, I merged snp_df into  pols_month_df, and then merged unemploy_df into the result. I used year and month_name as key variables to join them together. After merging three datasets, the dimension of the resulting dataset is `r nrow(polssnp_unem_df)` x `r ncol(polssnp_unem_df)`. The range years of the resulting dataset is `r range(polssnp_unem_df$year)`. The resulting dataset has `r ncol(polssnp_unem_df)` variables: `r names(polssnp_unem_df)`.
