Homework 2
================
Yiming Zhao

This is my solution for HW2

``` r
library(tidyverse)
```

    ## ── Attaching packages ────────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.1     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ───────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset.

``` r
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data for 2018 and 2017.

``` r
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017) 

precip_comb1718 = left_join(precip_df, month_df,by = "month") %>% 
  relocate(year, month, month_name)
```

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trash wheel collects that trash, and stores it into a dumpsters. The
dataset contains information on year, month, and trash collected,
includes some specific kinds of trash. There are a total of 344 rows in
our final trash wheel collection dataset. And the key variables for the
trash wheel collection dataset : dumpster, month, year, date,
weight\_tons, volume\_cubic\_yards, plastic\_bottles, polystyrene,
cigarette\_butts, glass\_bottles, grocery\_bags, chip\_bags,
sports\_balls, homes\_powered.

Additional data sheets include month precipitation data for year 2017
and year 2018 are presented in this file. There are a total of 24 rows
in our final month precipitation dataset. And the key variables for the
month precipitation dataset : month\_name, total and year.

For year 2018, the total precipitation is 70.33

The median number of sports balls in a dumpster in 2017 is 8

## Problem 2

Read and clean the data

``` r
nyc_tran_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE), vending = recode(vending, "YES" = TRUE, "NO" = FALSE))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

There are 19 variables containing in the dataset: line, station\_name,
station\_latitude, station\_longitude, route1, route2, route3, route4,
route5, route6, route7, route8, route9, route10, route11,
entrance\_type, entry, vending, ada.  
In order to clean dataset, I read the csv file at first. And then clean
its variable names. Next, I selected the interested variables from the
orginal dataset. Then I converted entry and vending variables from
character(YES/NO) to a logical variable. Finally, I got a 1868 x 19 size
of the resulting dataset. These data are tidy.

Identify distinct stations:

``` r
nyc_station = 
  distinct(nyc_tran_df, line, station_name, .keep_all = T)
```

• After calculation, there are 465 distinct stations, which are
identified by name and line.  
• Moreover, there are 84 distinct stations are ADA compliant.  
• As there are 183 stations entrances / exits that do not have vending,
and there are 69 stations entrances / exits that allow entrance but do
not have vendings, so the proportion of station entrances/exits without
vending allow entrance is 0.3770492

Reformat data

``` r
nyc_reform_df = 
  nyc_station %>% 
  mutate(route8 = as.character(route8), route9 = as.character(route9), 
         route10 = as.character(route10),route11 = as.character(route11)) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_name",
    values_to = "route_value"
  )
```

• There are 60 distinct stations serve the A train.  
• In addition, there are 17 distinct stations that serve the A train are
ADA compliant.

## Problem 3

First clean the data in pols-month.csv

``` r
pols_month_df = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  separate(mon, into = c("year", "month", "day")) %>% 
  mutate(month = as.numeric(month), 
         year = as.numeric((year)),
         president = ifelse(prez_dem == 1, "dem", "gop")) %>% 
  left_join(month_df, by = "month") %>%
  subset(select = c(-prez_dem, -prez_gop, -day, -month)) %>% 
  relocate(year, month_name)
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

Second, clean the data in snp.csv

``` r
snp_df = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  separate(date, into = c("month", "day", "year")) %>% 
  mutate(year = as.numeric(year),
         month = as.numeric(month)
         ) %>% 
  left_join(month_df, by = "month") %>% 
  arrange(year, month, .by_group = FALSE) %>% 
  relocate(year, month_name, day, close) %>% 
  subset(select = c(-month, -day))
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

Third tidy the unemployment data

``` r
month_abb_df = 
  tibble(
    month_abb = month.abb,
    month_name = month.name
    )

unemploy_df = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>%
  pivot_longer(
    Jan:Dec,
    names_to = "month_abb",
    values_to = "unemployment_value"
    ) %>% 
  left_join(month_abb_df, by = "month_abb") %>% 
  subset(select = -month_abb) %>% 
  janitor::clean_names() %>% 
  relocate(year, month_name) %>% 
  drop_na(unemployment_value)
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

Join the datasets by merging snp into pols, and merging unemployment
into the result

``` r
polssnp_unem_df = 
  left_join(pols_month_df, snp_df, by = c("year", "month_name")) %>% 
  left_join(unemploy_df,by = c("year", "month_name"))
```

For the pols\_month\_df dataset, it contains 9 variables from Jan.1947
to Jun.2015：year, month\_name, gov\_gop, sen\_gop, rep\_gop, gov\_dem,
sen\_dem, rep\_dem, president. For the snp\_df dataset, it contains
close values from Jan in 1950 to July in 2015. For unemploy\_df dataset,
it contains unemployment values from Jan in 1948 to Jun in 2015. After
cleaning above three datasets, I merged snp\_df into pols\_month\_df,
and then merged unemploy\_df into the result. I used year and
month\_name as key variables to join them together. After merging three
datasets, the dimension of the resulting dataset is 822 x 11. The range
years of the resulting dataset is 1947, 2015. The resulting dataset has
11 variables: year, month\_name, gov\_gop, sen\_gop, rep\_gop, gov\_dem,
sen\_dem, rep\_dem, president, close, unemployment\_value.
